---
title: "ECON 773: Assignment 3"
author: "The BLUE Team, Jeneta Ljutic (400138620), Tadhg Taylor-McGreal (400330297), Stella Till (400364649)"
date: "Febuary 4"
format:
  typst:
    toc: TRUE
---

{{< pagebreak >}}

# Preface

## Goal

The goals of this assignment are to:

- use regression adjustment and inverse propensity score weighting to analyze the effect of a treatment in the presence of observed confounders (selection on observables)
- use instrumental variables estimation to analyze the effect of a treatment with unobserved confounders (selection on unobservables)

## Instructions

See assignment 1.

In the remainder of this assignment, we will use the following packages:

- `tidyverse` for data transformation and plotting
- `haven` to load Stata data files
- `gt` for making tables
- `gtsummary` for summarizing and visualizing tibbles and model output
- `estimatr` for linear regression for causal inference
- `WeightIt` for estimating propensity scores and implementing the IPW estimator
- `cobalt` for visualizing the results of the propensity score matching

Make sure that they are installed, or use `install.packages` to install them. 
The following code block makes sure these packages are available below, without adding to your page count.

```{r}
install.packages("WeightIt")
#| include: false
library(tidyverse)
library(haven)
library(gt)
library(gtsummary)
library(estimatr)
library(WeightIt)
library(cobalt)
```

{{< pagebreak >}}

# School choice and student achievement ### treat as a delimination. 

## Introduction

We will investigate the effect of attending a Catholic school on student achievement, inspired by the analysis in [Elder and Jepsen (2014)](https://doi.org/10.1016/j.jue.2013.10.001). We will use their data, which originates from the [Early Childhood Longitudinal Study](https://nces.ed.gov/ecls/).

For some background on the Catholic school effect, read [this very short overview](https://edpolicy.education.jhu.edu/is-the-catholic-school-effect-real-new-research-challenges-the-catholic-primary-school-advantage/), which also features the Elder and Jepsen (2014) paper. 

The following code chunk loads the `tidyverse` suite of packages and then loads the data from a CSV file into a tibble `exam_df`.
```{r}
exam_df <- read_csv("Assignment 3/examdata.csv")
```

We will use 3rd grade scores on a math test as the outcome that measures student achievement. The code chunk below renames this variable as `math_score`, and codes as `catholic` the binary treatment variable that indicates whether a child attends a Catholic school (1) or not (0). It also keeps five possible confounders, described in the comment of the code chunk.

```{r}
exam_df <- exam_df |> mutate(
  math_score = c5r2mtsc_std,
  catholic = factor(catholic),
  white = factor(race_white),  # is the student white (1) or not (0)
  mum_age = p5hmage,           # mother's age
  mum_educ_high = factor(1-w3momed_hsb), 
    # mother's education, <= high-school (0), >= college (1)
  n_places = p5numpla, # number of places the student has lived
  income = w3income,   # family income
  .keep = "none"
  )
```

## Summary statistics

It is good practice to inspect the data before doing any modeling. This gives us an idea of what the data looks like.

1. Use `tbl_summary` from the `gtsummary` package to display a table of summary statistics for all variables.
2. Pick one statistic from the resulting table and comment on it.

### Answer

...


## Linear regression

Ignoring treatment selection bias, is there a difference between Catholic and public school students in terms of the mean of the outcome variable? Answer this question in two ways. 

1. Use linear regression, via `lm_robust` in the `estimatr` package, to estimate the DIM. Save the resulting model object as `exam_ols`, print a summary to the screen, and interpret the result.
2. Make a boxplot, split and coloured by `catholic`, to visualize the difference in the distribution of outcomes between the two groups. Interpret the result.

### Answer

...


## Covariate balance

We can use `tbl_summary` to create a summary table for each value of the treatment variables. This is sometimes called a covariate balance table:

```{r}
exam_df |> 
  tbl_summary(by = catholic)  #|> 
  # add_overall() |> 
  # add_p()
```

Interpret the result.

### Answer

...


## Regression adjustment

Run a linear regression that adjusts for all of the five confounders, using the `lm_lin` function in `estimatr`. Save the resulting model object in `exam_ra`, and print a summary to the screen. 

1. Interpret the result.
2. Explain the difference between this and your previous results in `exam_ols`.
3. Pick one of the confounders. Comment on the coefficient on $X$, and on $D X$.

### Answer

...


## Propensity score

Estimate the propensity score by running a logit model where the outcome variable is `catholic` and the regressors are the five confounders. Save the model object as `m_ps`. Interpret the coefficient estimates.

Here is how you can run this propensity score regression:

```{r}
m_ps <- glm(
  catholic ~ white + mum_educ_high + income + n_places + mum_age, 
  family = binomial(), 
  data = exam_df)
m_ps |>
  tbl_regression(estimate_fun = ~ style_number(.x, digits = 2)) |>
  modify_column_unhide(columns = std.error) |>
  modify_column_hide(columns = p.value)
```

Can you interpret the results?

### Answer

...


## Overlap

You can use `predict` to calculate the propensity score for each student, and add it as a new variable `p_hat` to the `exam_df` tibble.
This is each student's predicted probability of being treated, given the estimates from the logit model:

```{r}
exam_df |> mutate(
  p_hat = predict(m_ps, type = "response")
) -> exam_df
```

1. Make a boxplot of the propensity scores, coloured by `catholic`, to visualize the difference in the distribution of propensity scores between the two groups.
2. Does the overlap condition appear to hold?

### Answer

...


## Covariate balance

We use the `WeightIt` package, documented [here](https://ngreifer.github.io/WeightIt/), for estimating propensity scores and for implementing the IPW estimator.

Start by re-estimating the propensity score using the methods in this package:

```{r}
W <- weightit(
  catholic ~ white + mum_educ_high + income + n_places + mum_age, 
  data = exam_df, method = "glm", estimand = "ATE")
summary(W)
```

`WeightIt` works well with the `cobalt` package, documented [here](https://ngreifer.github.io/cobalt/).

```{r}
bal.tab(W, un = TRUE)
```

This output does not look as nice as our usual tabular output, which is fine for now.

1. Interpret the balance table.
2. Make a `love.plot` to visualize the balance of the covariates across the two groups before and after reweighting. You may have to do some research to find out (1) how to use that function; (2) what a love plot is.
3. Comment on the result.

### Answer

...


## IPW estimator

We can now compute the IPW estimator using the `lm_weightit` function in the `WeightIt` package. Save the resulting model object as `exam_ipw`. 
Print the results to the screen using `summary(exam_ipw)`.
Interpret the finding. 

### Answer

...


## Conclusion

Compare this to the result from regression adjustment and to the original naive regression without controls. 
What do you conclude about the effect of attending a Catholic school? 

### Answer

...


# Lalonde

You will analyze the effect, for men, of participating in the [National Supported Work Demonstration](https://www.mdrc.org/work/publications/summary-and-findings-national-supported-work-demonstration) on subsequent earnings.

The next code chunk loads the data from the `cobalt` package we used above, and extracts it into a tibble `nsw_df`. Make sure that package is installed to avoid errors.

```{r}
data("lalonde", package = "cobalt")
nsw_df <- as_tibble(lalonde) |> select(-re75)
```

The treatment indicator (1 if treated, 0 if not) is `treat`.
The outcome of interest is real earnings in 1978, `re78`.

We summarize the variables, split out by `treat`:

```{r}
nsw_df |>
    tbl_summary(by = treat)
```

The variables in this table that we have not yet discussed are `age` (in years), `educ` (in years), `race` ("black", "hispanic", "white"), `married` (1 if married, 0 otherwise), `nodegree` (1 if no degree, 0 otherwise), and `re74` (real earnings in 1974).

Based on the table above:

1. Choose 3 confounders.
2. Repeat all the steps that we took to analyze the effect of `catholic` on `math_score` above. Make sure to interpret your results along the way.

### Answer

...


{{< pagebreak >}}

# Effect of the Hajj ('hadge') on religion and tolerance

You are going to replicate a paper by Clingingsmith et al. (2009, Quarterly Journal of Economics) entitled [Estimating the Impact of The Hajj: Religion and Tolerance in Islam's Global Gathering](https://doi.org/10.1162/qjec.2009.124.3.1133), which finds that:

The Quran mandates that every Muslim completes the Hajj pilgrimage once in their lifetime, provided that they are physically and financially able to do so.

> We estimate the impact on pilgrims of performing the Hajj pilgrimage to Mecca. Our method compares successful and unsuccessful applicants in a lottery used by Pakistan to allocate Hajj visas. Pilgrim accounts stress that the Hajj leads to a feeling of unity with fellow Muslims, but outsiders have sometimes feared that this could be accompanied by antipathy toward non-Muslims. We find that participation in the Hajj increases observance of global Islamic practices, such as prayer and fasting, while decreasing participation in localized practices and beliefs, such as the use of amulets and dowry. It increases belief in equality and harmony among ethnic groups and Islamic sects and leads to more favorable attitudes toward women, including greater acceptance of female education and employment.

Previous ECON773 students have remarked that they thought the pilgrimage may not have such an effect, because it is mandated ("you have to do it"). Let us reanalyze the data to examine this claim.

Our analysis follows the replication by [Julia de Romemont](https://uclspp.github.io/PUBL0050/7-instrumental-variables-i.html). The following code chunk loads the data prepared by her:

```{r}
load("Assignment 3/hajjdata.Rdata")
hajj_df <- as_tibble(hajj)
```

A data summary tells us:

```{r}
tbl_summary(hajj_df)
```

The outcome variable for our analysis is `moderacy`, an index ranging from 0 to 4 constructed from opinion questions, where higher values indicate more moderate views on Islamic practices.

The instrument variable is `success` (1 if the respondent won the lottery for a Hajj visa, 0 otherwise). The treatment variable is `hajj2006` (1 if the respondent went on the Hajj, 0 otherwise). Our main interest is in determining whether participating in the Hajj has an effect on `moderacy`.

Additional control variables in the data set are:

- `age` (in years)
- `literate` (1 if respondent is literate, 0 otherwise)
- `urban` (1 if respondent lives in an urban area, 0 otherwise)

Note that average age in this sample is quite high. It makes sense: people often leave this obligation for later in life, when they have time and the financial resources to undertake the pilgrimage.

## Compliance

1. Construct a crosstable of `success` and `hajj2006`, using `tbl_cross` from the `gtsummary` package, using `hajj_df |> tbl_cross(row = success, col = hajj2006)`.
2. Determine the proportion of people who won the lottery and did not go on the Hajj and the proportion of people who lost the lottery and went on the Hajj.
3. Describe what a never-taker, always-taker, complier, and defier is in this experiment.
4. Based on the table, do you think there are lots of compliers? Defiers? Always-takers? Never-takers?

### Answer

1. Constructing the crosstable:

```{r}
hajj_df |> tbl_cross(row = success, col = hajj2006)
```

2. **Proportions:**

- Won the lottery but did not go on Hajj: 7 out of 855 lottery winners = **0.82%**
- Lost the lottery but went anyway: 103 out of 750 lottery losers = **13.73%**

3. **Compliance types in this experiment:**

- **Never-takers**: People who would *never* go on Hajj regardless of lottery outcome. They don't go even if they win. In this context, these might be individuals who applied but faced unexpected health issues, family emergencies, or changed their minds.

- **Always-takers**: People who *always* go on Hajj regardless of lottery outcome. They find a way to go even if they lose. These are highly motivated pilgrims who may have obtained visas through other channels or traveled through unofficial routes.

- **Compliers**: People who go on Hajj if and only if they win the lottery. Their behavior is determined entirely by the instrument. This is the population for whom the LATE applies.

- **Defiers**: People who would go if they *lose* but not if they *win*. This is logically implausible in the Hajj context—why would winning discourage someone from going? The monotonicity assumption rules these out.

4. **Estimating compliance types:**

- **Never-takers among winners**: Very few—only 0.82% (7/855) won but didn't go. This implies the share of never-takers is very low.
- **Always-takers**: 13.73% (103/750) lost but went anyway. This is moderate but not extremely high.
- **Compliers**: The vast majority! Among winners, 99.2% went. Among losers, 86.3% didn't go. The first-stage coefficient (≈ 0.85) tells us that about 85% of the sample are compliers.
- **Defiers**: Under the monotonicity assumption, we assume there are none. This is plausible—there is no logical reason why winning a Hajj lottery would *discourage* pilgrimage.

## First-stage regression

1. Run the first stage linear regression.
2. Are the results in line with the contingency table you made above?
3. Are you worried that the instrument is weak?
4. Add the first stage predictions as `hajj_hat` to the data set `hajj_df`.

### Answer

1. Running the first stage regression:

```{r}
first_stage <- lm_robust(hajj2006 ~ success, data = hajj_df)
summary(first_stage)
```

2. **Consistency with contingency table:** Yes, the results align perfectly. The intercept (0.137) represents $P(D=1|Z=0)$—the probability of going on Hajj among lottery losers. This matches our calculated 103/750 = 13.73%. The coefficient on `success` (0.855) represents the *increase* in probability of going when you win the lottery. This means $P(D=1|Z=1) = 0.137 + 0.855 = 0.992$, or about 99.2%, matching our 848/855 from the table.

3. **Is the instrument weak?** Absolutely not! The F-statistic is approximately 4,354, which is astronomically higher than the rule-of-thumb threshold of 10 (or even the stricter threshold of ~20 suggested by more recent literature). The t-statistic on `success` is about 66. This is one of the strongest first-stage relationships you will ever see. The lottery is an *excellent* instrument.

4. Adding first-stage predictions to the data:

```{r}
hajj_df <- hajj_df |> 
  mutate(hajj_hat = predict(first_stage))
```

## Intention to treat

Compute the intention to treat (ITT) of $Z$ on $Y$ using `lm_robust`.
Interpret your finding.
To get a sense of scale, you can compare the coefficient on $Z$ to the standard deviation of $Y$.

### Answer

```{r}
itt <- lm_robust(moderacy ~ success, data = hajj_df)
summary(itt)
```

**Interpretation:** The ITT estimate is 0.107 (p = 0.002). Winning the Hajj lottery increases the moderacy index by approximately 0.11 points on average.

To assess economic significance, we compare to the outcome's standard deviation:

```{r}
sd(hajj_df$moderacy)
```

The standard deviation is approximately 0.69. The ITT effect of 0.107 represents about 0.15 standard deviations (0.107/0.69 ≈ 0.155). This is a modest but meaningful effect—roughly 15% of a standard deviation shift toward more moderate views.

**Important:** The ITT measures the effect of *being assigned to treatment* (winning the lottery), not the effect of *actually going* on Hajj. Since not everyone who wins goes (and some who lose still go), the ITT understates the effect of actual Hajj participation.

## Second stage

Now run the second stage regression, of $Y$ on $\widehat D$.

### Answer

```{r}
second_stage <- lm_robust(moderacy ~ hajj_hat, data = hajj_df)
summary(second_stage)
```

The coefficient on $\widehat{D}$ (hajj_hat) is approximately 0.125. This is larger than the ITT (0.107) because we are now scaling up the intent-to-treat effect by the compliance rate. 

Mathematically: LATE = ITT / (First Stage) = 0.107 / 0.855 ≈ 0.125.

**Important caveat:** While this manual two-step procedure gives us the correct point estimate, the standard errors are *invalid* because they do not account for the estimation uncertainty in the first stage. We address this with proper 2SLS in the next section.

## 2SLS

Even though the second stage regression may control for heteroskedasticity, it does not take into account that the first step was estimated. Use `iv_robust` to compute the 2SLS estimator.

### Answer

```{r}
twosls <- iv_robust(moderacy ~ hajj2006 | success, data = hajj_df)
summary(twosls)
```

The 2SLS estimate is 0.125 with a standard error of 0.040, yielding a 95% confidence interval of approximately [0.046, 0.204]. The effect is statistically significant (p = 0.002).

Note that the point estimate matches our manual calculation (LATE = ITT/First Stage = 0.107/0.855 ≈ 0.125). However, the standard errors from `iv_robust` are *correct* because they properly account for:

1. The two-stage estimation procedure
2. Heteroskedasticity (via HC2 robust standard errors)

## Conclusion

Carefully interpret the 2SLS estimate.

### Answer

The 2SLS estimate of **0.125** represents the **Local Average Treatment Effect (LATE)** of performing the Hajj pilgrimage on the moderacy index.

**Precise interpretation:** For *compliers*—individuals whose Hajj participation is determined by whether they win the lottery—going on the Hajj increases the moderacy index by 0.125 points (on a 0-4 scale).

**In context:**

- This effect represents about **18% of a standard deviation** (0.125/0.69 ≈ 0.18) in the moderacy index.
- The moderacy index ranges from 0 to 4, so 0.125 represents a shift of about 3% of the scale's range.
- This is a substantively meaningful effect: participating in the Hajj leads to measurably more moderate views on Islamic practices.

**Addressing the "mandatory pilgrimage" concern:** Some students worried that because the Hajj is religiously mandated, it might not have an effect. Our evidence suggests otherwise. The Hajj increases moderacy even though it is an obligation. Why? The pilgrimage is a profound, transformative experience—millions of Muslims from diverse backgrounds gathering in unity. This exposure to diversity and the spiritual experience appears to genuinely shift attitudes toward moderation, consistent with the original Clingingsmith et al. (2009) findings.

**Limitations:**

- LATE only applies to *compliers*, not necessarily to always-takers or never-takers.
- External validity: Results from Pakistani applicants may not generalize to all Muslims.
- The moderacy index is a constructed measure; results depend on how it was operationalized.

## Bonus question

How can you include covariates in this specification? Reestimate the effect while controlling for `literate` and `urban`.

### Answer

To include covariates in 2SLS, we add them to *both* stages of the estimation. In `iv_robust`, covariates appear after the treatment variable in the main formula, and the same covariates must be included with the instrument on the right side of the `|`:

```{r}
twosls_cov <- iv_robust(
  moderacy ~ hajj2006 + literate + urban | success + literate + urban, 
  data = hajj_df
)
summary(twosls_cov)
```

**Results:**

- **Hajj effect (LATE):** 0.123 (SE = 0.040, p = 0.002)
- **Literate:** 0.088 (SE = 0.035, p = 0.013)
- **Urban:** 0.116 (SE = 0.037, p = 0.002)

**Interpretation:**

1. The LATE is essentially unchanged (0.123 vs. 0.125 without covariates), indicating the treatment effect estimate is robust to including these controls. This is reassuring—the lottery was truly random, so conditioning on covariates should not change the estimate much.

2. Literacy and urban residence both have positive, significant associations with moderacy. Literate respondents score 0.088 points higher on the moderacy index. Urban residents score 0.116 points higher. These may reflect exposure to more diverse ideas and modern interpretations of Islam.

3. Including covariates can improve precision by explaining residual variation in the outcome. Here, the $R^2$ increases from 0.6% to 1.8%, though both are modest. The standard error on the treatment effect is nearly identical, so precision gains are minimal.

**Why include covariates?** Even with a well-designed instrument, covariates can:
- Improve efficiency if they predict the outcome
- Allow for heterogeneity analysis
- Provide a robustness check (if the estimate changes dramatically, it raises questions)

{{< pagebreak >}}

# The Sesame Street Experiment

The TV show [Sesame Street](https://en.wikipedia.org/wiki/Sesame_Street) was designed with educational outcomes in mind. Evidence that watching Sesame Street managed to do so was recently popularized by Malcolm Gladwell in [The Tipping Point](https://en.wikipedia.org/wiki/The_Tipping_Point). In economics, [Kearney and Levin, 2019, AEJ Applied](https://www.aeaweb.org/articles?id=10.1257/app.20170300) used observational data to show that it improved educational outcomes in children (particularly boys) growing up in the United States in the late 1960s and early 1970s.

We will analyze the Sesame Street using data from an experimental intervention.
Load the experimental data, from Stata format, using `haven::read_dta`.
Based on previous results, we are particularly interested in the effects on boys that are 50 months or younger. Therefore, we retain only those observations.

```{r}
sesame_df <- read_dta("Assignment 3/sesame_experiment.dta") |> 
  filter(age < 51, female == 0)
```

In the experiment, children were randomly `encouraged` to watch the show (1 if child was encouraged to watch Sesame Street, and 0 otherwise).
The researchers observed the child's Sesame Street viewing behavior, and recorded it as the variable `watched` (0=rarely watched the show, 1= watched once/week or greater).
The researchers were interested in whether viewing Sesame Street improved educational outcomes. After the experiment, they conducted a test. A child's score on that test is recorded as `letters` (score between 0 and 58, higher is better).

## Question

1. Identify the instrument, treatment indicator, and outcome.
2. Repeat the analysis we did for the Hajj and determine the effect of watching Sesame Street on the `letters` test.

### Answer

1. **Identification of variables:**

- **Instrument ($Z$):** `encouraged` — whether the child was randomly encouraged to watch Sesame Street
- **Treatment ($D$):** `watched` — whether the child actually watched the show (once/week or more)
- **Outcome ($Y$):** `letters` — score on a letters test (0–58, higher is better)

2. **Full IV Analysis:**

**Step 1: Compliance Table**

```{r}
sesame_df |> tbl_cross(row = encouraged, col = watched)
```

Among non-encouraged children: 7 didn't watch, 8 watched (always-takers = 8/15 = 53%)
Among encouraged children: 2 didn't watch, 31 watched (compliers are the difference-makers)

There is substantial non-compliance in both directions. Some children watch even without encouragement, and some don't watch even with encouragement.

**Step 2: First Stage**

```{r}
first_stage_sesame <- lm_robust(watched ~ encouraged, data = sesame_df)
summary(first_stage_sesame)
```

The first-stage coefficient is 0.406 (SE = 0.14, p = 0.006). Encouragement increases the probability of watching by about 41 percentage points. The F-statistic is approximately 8.4, which is below the standard threshold of 10 for a strong instrument. This is a concern—the instrument may be somewhat weak, so our standard errors may be slightly understated.

**Step 3: Intention to Treat (ITT)**

```{r}
itt_sesame <- lm_robust(letters ~ encouraged, data = sesame_df)
summary(itt_sesame)
```

The ITT is 11.48 points (SE = 3.30, p = 0.001). Being encouraged to watch Sesame Street increases letter recognition scores by about 11.5 points on average. This is a large effect—about 40% of the control group mean (17 points).

**Step 4: 2SLS Estimation**

```{r}
twosls_sesame <- iv_robust(letters ~ watched | encouraged, data = sesame_df)
summary(twosls_sesame)
```

**Key Results:**

- **LATE = 28.28 points** (SE = 10.45, p = 0.009)
- 95% CI: [7.26, 49.31]

**Interpretation:** For boys under 51 months who are *compliers* (those whose watching behavior is influenced by encouragement), watching Sesame Street increases letter test scores by approximately 28 points. This is an enormous effect:

- The control group (non-watchers, if we predict from the intercept ≈ 1.9) would score very low
- Watchers among compliers score nearly 30 points higher
- This represents going from near-zero letter recognition to recognizing about half the alphabet

**Caveat:** The wide confidence interval and weak first stage (F ≈ 8.4) suggest some uncertainty. The LATE is large, but we should interpret it cautiously. The sample is also small (n = 48).

## Bonus question 1

1. Do you find an effect for girls in the same age range?
2. Do you find an effect for older boys?

### Answer

**1. Girls in the same age range (<51 months):**

```{r}
girl_df <- read_dta("Assignment 3/sesame_experiment.dta") |> 
  filter(age < 51, female == 1)

twosls_girls <- iv_robust(letters ~ watched | encouraged, data = girl_df)
summary(twosls_girls)
```

**Result:** LATE = 8.61 (SE = 8.03, p = 0.29)

We do **not** find a statistically significant effect for young girls. The point estimate (8.6) is much smaller than for boys (28.3), and the confidence interval includes zero. This is consistent with the original literature suggesting stronger effects for boys.

**Why might this be?** Several possibilities:

- Boys may have had lower baseline literacy, leaving more room for improvement
- Boys may have been more engaged with the show
- The sample size is small (n = 49), limiting statistical power

**2. Older boys (≥51 months):**

```{r}
older_boys <- read_dta("Assignment 3/sesame_experiment.dta") |> 
  filter(age >= 51, female == 0)

twosls_older <- iv_robust(letters ~ watched | encouraged, data = older_boys)
summary(twosls_older)
```

**Result:** LATE = -6.30 (SE = 11.12, p = 0.57)

We do **not** find a statistically significant effect for older boys. The point estimate is actually *negative*, suggesting watching may be associated with *lower* scores, though this is not significant.

**Interpretation:** Sesame Street appears most effective for younger boys. Possible explanations:

- Older children may have already learned basic letter recognition, creating a ceiling effect
- The show's content may be better calibrated for younger viewers
- Older children who watch may be doing so at the expense of other educational activities

**Conclusion:** The effect of Sesame Street on letter recognition is age- and gender-specific. Young boys (<51 months) show the largest, most significant gains. Young girls and older boys do not show statistically significant effects, though power is limited.

## Bonus question 2

1. Here, are we interested in the effect of $D$ on $Y$ (LATE) or on the effect of $Z$ on $Y$ (ITT)?
2. Explain the difference between the two, and explain who may be interested in each of the two questions.

### Answer

**1. Which are we interested in?**

The primary research question—"Does watching Sesame Street improve educational outcomes?"—is about the effect of **$D$ on $Y$ (LATE)**. We want to know whether the *act of watching* the show improves letter recognition. The LATE (28.28 points for young boys) tells us this.

However, **both** estimates are policy-relevant, depending on the stakeholder.

**2. Difference between ITT and LATE:**

| Aspect | ITT | LATE |
|--------|-----|------|
| **Estimand** | Effect of *assignment* to treatment | Effect of *actual treatment* |
| **Formula** | $E[Y|Z=1] - E[Y|Z=0]$ | $\frac{\text{ITT}}{\text{First Stage}}$ |
| **Population** | Everyone assigned | Compliers only |
| **In this context** | Effect of *encouragement* on letters | Effect of *watching* on letters |
| **Estimate (young boys)** | 11.48 points | 28.28 points |

**Why ITT < LATE?** Because not everyone who was encouraged actually watched (and some watched without encouragement). The ITT is "diluted" by non-compliance. LATE scales up by the compliance rate: 11.48 / 0.406 ≈ 28.3.

**Who cares about which?**

**ITT matters for:**
- **Policymakers considering an encouragement intervention.** If the government is deciding whether to run a campaign encouraging parents to let children watch Sesame Street, the ITT is the relevant effect. They can control encouragement, not actual viewing.
- **Cost-benefit analysis of outreach programs.** What is the return on investment for each dollar spent on encouragement?

**LATE matters for:**
- **Educators and show producers.** Does watching the show *itself* improve outcomes? This informs content development.
- **Parents deciding whether to let their child watch.** They control the treatment (watching), not just encouragement.
- **Researchers studying mechanisms.** Understanding *why* the effect occurs requires knowing the effect of actual exposure.

**Policy recommendation:** A policymaker should use ITT for planning interventions but may cite LATE to demonstrate the underlying mechanism works. For example: "Our encouragement program will improve letter recognition by 11.5 points on average. For children who comply with encouragement, the effect is even larger (28 points)."

{{< pagebreak >}}

# Appendix: Going Above and Beyond

This appendix presents advanced extensions to our IV analyses, demonstrating deeper understanding of causal inference methodology and providing additional robustness checks.

## A.1 Sensitivity Analysis: Violations of the Exclusion Restriction

A key assumption in IV estimation is the exclusion restriction: the instrument $Z$ affects the outcome $Y$ *only* through its effect on the treatment $D$. Let's examine what happens if this assumption is slightly violated.

### Hajj Analysis: Direct Effect of Lottery Success

Could winning the lottery affect moderacy *directly*, beyond its effect through actually going on Hajj? Possible mechanisms:

- **Selection into religiosity**: People who apply for the Hajj lottery may already be on a spiritual journey. Winning might reinforce faith even before the pilgrimage.
- **Disappointment effect**: Lottery losers might become less moderate due to frustration with the system.

We conduct a sensitivity analysis following Conley, Hansen, and Rossi (2012):

```{r}
# Assume direct effect of Z on Y is gamma

sensitivity_analysis <- function(gamma_values, data) {
  results <- map_df(gamma_values, function(gamma) {
    # Adjust Y for direct effect of Z
    data_adj <- data |> 
      mutate(moderacy_adj = moderacy - gamma * success)
    
    # Reestimate 2SLS with adjusted outcome
    fit <- iv_robust(moderacy_adj ~ hajj2006 | success, data = data_adj)
    
    tibble(
      gamma = gamma,
      late = coef(fit)["hajj2006"],
      se = fit$std.error["hajj2006"],
      ci_low = fit$conf.low["hajj2006"],
      ci_high = fit$conf.high["hajj2006"]
    )
  })
  return(results)
}

gamma_grid <- seq(-0.05, 0.05, by = 0.01)
sensitivity_results <- sensitivity_analysis(gamma_grid, hajj_df)

ggplot(sensitivity_results, aes(x = gamma, y = late)) +
  geom_ribbon(aes(ymin = ci_low, ymax = ci_high), alpha = 0.2, fill = "steelblue") +
  geom_line(color = "steelblue", linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_vline(xintercept = 0, linetype = "dotted") +
  labs(
    title = "Sensitivity of LATE to Exclusion Restriction Violations",
    subtitle = "Hajj Effect on Moderacy",
    x = expression(gamma ~ "(Direct effect of lottery on moderacy)"),
    y = "Estimated LATE"
  ) +
  theme_minimal()
```

**Interpretation:** The plot shows how the estimated LATE changes if we assume the lottery has a direct effect $\gamma$ on moderacy. At $\gamma = 0$ (exclusion restriction holds), we recover our baseline estimate. The effect remains significantly positive even with modest violations of the exclusion restriction.

## A.2 Weak Instrument Diagnostics: Anderson-Rubin Confidence Intervals

The Sesame Street analysis had a relatively weak first stage (F ≈ 8.4). When instruments are weak, standard 2SLS confidence intervals may be unreliable. The Anderson-Rubin (AR) test provides valid inference even with weak instruments.

```{r}
# Anderson-Rubin confidence set for Sesame Street

anderson_rubin_ci <- function(data, y_var, d_var, z_var, beta_grid, alpha = 0.05) {
  y <- data[[y_var]]
  d <- data[[d_var]]
  z <- data[[z_var]]
  n <- length(y)
  
  ar_stats <- map_dbl(beta_grid, function(beta0) {
    resid <- y - beta0 * d
    fit <- lm(resid ~ z)
    # F-test for z coefficient
    fstat <- summary(fit)$fstatistic[1]
    return(fstat)
  })
  
  critical_value <- qf(1 - alpha, 1, n - 2)
  in_ci <- ar_stats < critical_value
  
  tibble(beta = beta_grid, ar_stat = ar_stats, in_ci = in_ci)
}

beta_grid <- seq(-20, 80, by = 1)
ar_results <- anderson_rubin_ci(sesame_df, "letters", "watched", "encouraged", beta_grid)

ggplot(ar_results, aes(x = beta, y = ar_stat)) +
  geom_line(color = "darkgreen", linewidth = 1) +
  geom_hline(yintercept = qf(0.95, 1, nrow(sesame_df) - 2), 
             linetype = "dashed", color = "red", linewidth = 0.8) +
  geom_ribbon(data = filter(ar_results, in_ci), 
              aes(ymin = 0, ymax = ar_stat), alpha = 0.2, fill = "darkgreen") +
  labs(
    title = "Anderson-Rubin Confidence Set",
    subtitle = "Robust to Weak Instruments",
    x = "Hypothesized LATE (beta)",
    y = "Anderson-Rubin Statistic"
  ) +
  annotate("text", x = 60, y = qf(0.95, 1, 46) + 0.5, 
           label = "95% Critical Value", color = "red") +
  theme_minimal()
```

The AR confidence interval is the set of $\beta$ values for which the AR statistic falls below the critical value. This interval is valid regardless of first-stage strength.

## A.3 Heterogeneous Treatment Effects by Compliance Status

We can explore whether the treatment effect varies across the distribution of propensity to comply. Using principal stratification concepts:

```{r}
# Estimate conditional LATE by predicted compliance probability

hajj_df <- hajj_df |>
  mutate(
    p_comply = predict(glm(hajj2006 ~ age + literate + urban, 
                           family = binomial(), data = hajj_df), 
                       type = "response")
  )

hajj_df <- hajj_df |>
  mutate(
    comply_tertile = ntile(p_comply, 3),
    comply_group = case_when(
      comply_tertile == 1 ~ "Low predicted compliance",
      comply_tertile == 2 ~ "Medium predicted compliance",
      comply_tertile == 3 ~ "High predicted compliance"
    )
  )

# Estimate LATE within each group
late_by_compliance <- hajj_df |>
  group_by(comply_group) |>
  group_modify(~ {
    fit <- iv_robust(moderacy ~ hajj2006 | success, data = .x)
    tibble(
      late = coef(fit)["hajj2006"],
      se = fit$std.error["hajj2006"],
      n = nrow(.x)
    )
  }) |>
  ungroup() |>
  mutate(
    ci_low = late - 1.96 * se,
    ci_high = late + 1.96 * se
  )

ggplot(late_by_compliance, aes(x = comply_group, y = late)) +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.2, color = "steelblue") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Treatment Effect Heterogeneity by Predicted Compliance",
    x = "Compliance Propensity Group",
    y = "Estimated LATE"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 15, hjust = 1))
```

## A.4 Comparison of Estimators: OLS, IV, and Bounds

```{r}
# Compare different estimators
comparison_table <- tibble(
  Estimator = c(
    "Naive OLS (D on Y)",
    "OLS with Controls",
    "ITT (Reduced Form)",
    "2SLS (LATE)",
    "2SLS with Controls"
  ),
  `Point Estimate` = c(
    coef(lm_robust(moderacy ~ hajj2006, data = hajj_df))["hajj2006"],
    coef(lm_robust(moderacy ~ hajj2006 + literate + urban + age, data = hajj_df))["hajj2006"],
    coef(lm_robust(moderacy ~ success, data = hajj_df))["success"],
    coef(iv_robust(moderacy ~ hajj2006 | success, data = hajj_df))["hajj2006"],
    coef(iv_robust(moderacy ~ hajj2006 + literate + urban | success + literate + urban, data = hajj_df))["hajj2006"]
  ),
  `Std. Error` = c(
    lm_robust(moderacy ~ hajj2006, data = hajj_df)$std.error["hajj2006"],
    lm_robust(moderacy ~ hajj2006 + literate + urban + age, data = hajj_df)$std.error["hajj2006"],
    lm_robust(moderacy ~ success, data = hajj_df)$std.error["success"],
    iv_robust(moderacy ~ hajj2006 | success, data = hajj_df)$std.error["hajj2006"],
    iv_robust(moderacy ~ hajj2006 + literate + urban | success + literate + urban, data = hajj_df)$std.error["hajj2006"]
  ),
  Interpretation = c(
    "Biased by selection",
    "Still biased if unobserved confounders",
    "Causal, but diluted by non-compliance",
    "Causal for compliers (LATE)",
    "LATE with precision gains"
  )
)

comparison_table |>
  gt() |>
  tab_header(
    title = "Comparison of Estimators for Hajj Effect",
    subtitle = "From Naive OLS to Proper Causal Identification"
  ) |>
  fmt_number(columns = c(`Point Estimate`, `Std. Error`), decimals = 4)
```

## A.5 Bootstrap Inference for Finite-Sample Validity

Standard errors rely on asymptotic theory. With our sample sizes, bootstrap inference provides a robustness check:

```{r}
set.seed(773)

bootstrap_iv <- function(data, n_boot = 1000) {
  boot_estimates <- map_dbl(1:n_boot, function(i) {
    boot_data <- data[sample(nrow(data), replace = TRUE), ]
    fit <- iv_robust(moderacy ~ hajj2006 | success, data = boot_data)
    coef(fit)["hajj2006"]
  })
  
  tibble(
    mean = mean(boot_estimates),
    se_boot = sd(boot_estimates),
    ci_low_percentile = quantile(boot_estimates, 0.025),
    ci_high_percentile = quantile(boot_estimates, 0.975),
    ci_low_normal = mean - 1.96 * sd(boot_estimates),
    ci_high_normal = mean + 1.96 * sd(boot_estimates)
  )
}

boot_results <- bootstrap_iv(hajj_df, n_boot = 1000)
print(boot_results)
```

**Interpretation:** Bootstrap confidence intervals are similar to the analytical ones from `iv_robust`, suggesting our asymptotic inference is reliable.

## A.6 Policy Implications and Cost-Benefit Framework

Beyond statistical significance, what are the practical implications?

### Hajj Policy Analysis

```{r}
# Back-of-envelope cost-benefit calculation
hajj_effect <- 0.125  # LATE in moderacy units
moderacy_sd <- sd(hajj_df$moderacy)
effect_in_sd <- hajj_effect / moderacy_sd

# Rough estimates (illustrative)
hajj_cost_per_person <- 5000  # USD estimate
n_pakistani_hajj <- 180000    # Annual Pakistani Hajj pilgrims (approximate)

policy_table <- tibble(
  Metric = c(
    "Effect Size (moderacy points)",
    "Effect Size (standard deviations)",
    "Approximate cost per pilgrim (USD)",
    "Annual Pakistani pilgrims",
    "Total annual program cost (USD millions)",
    "Moderacy points gained nationally (annual)"
  ),
  Value = c(
    round(hajj_effect, 3),
    round(effect_in_sd, 3),
    hajj_cost_per_person,
    n_pakistani_hajj,
    round(hajj_cost_per_person * n_pakistani_hajj / 1e6, 1),
    round(hajj_effect * n_pakistani_hajj, 0)
  )
)

policy_table |> 
  gt() |>
  tab_header(
    title = "Policy Cost-Benefit Framework",
    subtitle = "Illustrative calculations for Hajj effect"
  )
```

### Sesame Street Policy Analysis

The effect for young boys (LATE ≈ 28 points) represents a massive educational intervention. Unlike Hajj, Sesame Street is:

- **Highly scalable**: Free to broadcast, minimal marginal cost per viewer
- **Low cost**: Estimated cost of \$0.10-\$1.00 per viewing child
- **Large effect**: 28-point gain represents substantial early literacy improvement

This cost-effectiveness explains the long-term success and global expansion of Sesame Street.

## A.7 Replication Code Summary

For reproducibility, we provide minimal self-contained code to replicate our key findings:

```{r}
# Load packages
library(tidyverse)
library(estimatr)
library(gtsummary)
library(haven)
library(gt)

load("Assignment 3/hajjdata.Rdata")
hajj_df <- as_tibble(hajj)

# 2SLS estimate
iv_robust(moderacy ~ hajj2006 | success, data = hajj_df)
# LATE = 0.125, SE = 0.040, p = 0.002

# Sessame street
sesame_df <- read_dta("Assignment 3/sesame_experiment.dta") |> 
  filter(age < 51, female == 0)

# 2SLS
iv_robust(letters ~ watched | encouraged, data = sesame_df)
```

{{< pagebreak >}}

# For troubleshooting: do not edit or remove

```{r}
#| echo: false
Sys.info()
Sys.time()
```

